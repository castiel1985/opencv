为什么用交叉验证法？
交叉验证用于评估模型的预测性能，尤其是训练好的模型在新数据上的表现，可以在一定程度上减小过拟合。
还可以从有限的数据中获取尽可能多的有效信息。


需求：
以多元回归模型为例：，应该如何确定k的大小，使得该模型对解决相应的分类问题最为有效？如何在偏倚（bias）和方差（variance）之间寻求最佳的平衡点？
更进一步，我们同样需要知道如何在加权回归模型中选择适当的波长参数，或者在基于范式的SVM模型中选择适当的参数C？

假设模型集合为有限集，我们的目的就是从这d个模型中，选择最有效的模型。
假设样本集为S，根据经验风险最小化原则（ERM），可能会使用这样的算法：
1.在S上训练每个模型，得到相应的假设函数；
2.选择训练误差最小的假设函数，即为我们需要的函数。
然而，这样的算法实际上并不有效。以多元回归模型为例，指数越高，对样本集S的拟合就越准确，这样虽然保证了较低的训练误差，
但是这种方法会使泛化误差变得很大，因此，这并不是一个好的方法。

（一）
简单交叉验证（simple cross validation）：
随机将S分为（例如70%的样本）和（剩下30%的样本），这里称作简单交叉验证集：
1.在上训练每个模型，得到相应的假设函数；
2.将每个假设函数通过交叉验证集进行验证，选择使得训练误差最小的；
3.通过简单交叉验证，可以得到每个假设函数的真实的泛化误差，从而可以选择泛化误差最小的那个假设函数。
通常，预留1/4-1/3的样本作为交叉验证集，而剩下的作为训练集使用。
步骤3也可以替换成这样的操作：选择相应的模型，使得训练误差最小，然后在用对整个样本集S进行训练。使用这样的方法原因是有的学习算法对于初试的条件非常敏感，
因此，他也许在上表现良好，但是在整个样本集中却存在很大的误差，因此需要再次带入整个样本集进行验证。

不足之处在于：此方法浪费了中的数据，即使我们将模型再次带入整个样本集，我们仍然只用了70%的样本建模。如果样本的采集非常的容易以致样本量非常之大，使用交叉验证方法没有什么问题；
但如果样本非常稀缺，采集困难，那么我们就需要考虑一种能够充分利用样本的方法。

（二）
k-折交叉验证：    将样本集随机划分为k份，k-1份作为训练集，1份作为验证集，依次轮换训练集和验证集k次，验证误差最小的模型为所求模型。
具体方法如下：

1.随机将样本集S划分成k个不相交的子集，每个子集中样本数量为m/k个，这些子集分别记作；

2.对于每个模型，进行如下操作：

for j=1 to k

将作为训练集，训练模型，得到相应的假设函数。

再将作为验证集，计算泛化误差；

3.计算每个模型的平均泛化误差，选择泛化误差最小的模型。


K-折交叉验证方法，每次留作验证的为总样本量的1/k(通常取k=10)，因此每次用于训练的样本量相应增加了，然而K-折交叉验证对于每个模型都需要运行k次，他的计算成本还是较高的。
还有一种k-折交叉验证的极端形式，当k=m时，即把样本集S划分为m个子集，其中的m-1个样本作为训练集，剩下1个样本作为验证集，如此循环m次，选取验证误差最小的模型。
以上介绍的各种交叉验证的方法，可用于模型的选择，但也可以针对单个算法和模型进行评价。

小结：交叉验证是一种模型选择方法，其将样本的一部分用于训练，另一部分用于验证。因此不仅考虑了训练误差，同时也考虑了泛化误差。从这里可以看出机器学习、数据挖掘与传统统计学的一个重要差别：传统统计学更注重理论，追求理论的完整性和模型的精确性，
在对样本建立某个特定模型后，用理论去对模型进行各种验证；而机器学习/数据挖掘则注重经验，如交叉验证，就是通过不同模型在同一样本上的误差表现好坏，来选择适合这一样本的模型，而不去纠结理论上是否严谨。
