(1)10折交叉验证（来自第六章）
代码：
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold

#创建模型 for scikit-learn
model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10, verbose=0)

# 10折交叉验证
kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)
results = cross_val_score(model, x, Y, cv=kfold)








(2)GridSearchCV 模型调参： 需要一个字典类型的字段作为需要调参的参数------------调参
代码：

from sklearn.model_selection import GridSearchCV
from keras.wrappers.scikit_learn import KerasClassifier

# 构建需要调参的参数
param_grid = {}
param_grid['optimizer'] = ['rmsprop', 'adam']
param_grid['init'] = ['glorot_uniform', 'normal', 'uniform']
param_grid['epochs'] = [50, 100, 150, 200]
param_grid['batch_size'] = [5, 10, 20]

# 调参
grid = GridSearchCV(estimator=model, param_grid=param_grid)
results = grid.fit(x, Y)

# 输出结果
print('Best: %f using %s' % (results.best_score_, results.best_params_))
means = results.cv_results_['mean_test_score']
stds = results.cv_results_['std_test_score']
params = results.cv_results_['params']

for mean, std, param in zip(means, stds, params):
    print('%f (%f) with: %r' % (mean, std, param))






(3)Pipline 便于交叉验证的每一个折中执行数据标准化处理 --------------数据标准化
# 数据正态化，改进算法
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

steps = []
steps.append(('standardize', StandardScaler()))
steps.append(('mlp', model))
pipeline = Pipeline(steps)
kfold = KFold(n_splits=10, shuffle=True, random_state=seed)
results = cross_val_score(pipeline, x, Y, cv=kfold)
print('Standardize: %.2f (%.2f) MSE' % (results.mean(), results.std()))





(4) StandardScaler()
构建神经网络模型，对数据进行标准化处理是一种很好的数据准备方法。
数据标准化是对数据进行缩放，使得每个属性的平均值为0，标准差为1，且使得数据保持高斯分布。同时对每个属性的中心倾向进行规范化，因为数据标准化后符合高斯分布，又叫数据正态化。
new_x = StandardScaler().fit_transform(x)



